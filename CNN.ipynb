{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sofiaif/detecciondefuego/blob/main/CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j7QOYje9ZBaY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 398
        },
        "outputId": "9359a2c6-4a7c-4e83-9135-1620f65b0204"
      },
      "source": [
        "import numpy as np\n",
        "from keras.preprocessing.image import load_img, img_to_array\n",
        "from keras.models import load_model\n",
        "\n",
        "#cargamos los archivos que entrenamos para reutilizar nuestra red enuronal\n",
        "longitud, altura = 150, 150\n",
        "modelo = './modelo/modelo.h5'\n",
        "pesos_modelo = './modelo/pesos.h5'\n",
        "cnn = load_model(modelo)\n",
        "cnn.load_weights(pesos_modelo)\n",
        "\n",
        "\n",
        "#recibe el nomber de la imagen y nos dice clase de objeto que es\n",
        "def predict(file):\n",
        "  x = load_img(file, target_size=(longitud, altura))# a x le cargamosla imagen que queremos que nos prediga\n",
        "  x = img_to_array(x)#convertimos la imagen en un arrglo\n",
        "  x = np.expand_dims(x, axis=0)\n",
        "  array = cnn.predict(x)\n",
        "  result = array[0]\n",
        "  answer = np.argmax(result)\n",
        "  if answer == 0:\n",
        "    print(\"pred: Perro\")\n",
        "  elif answer == 1:\n",
        "    print(\"pred: Gato\")\n",
        "  elif answer == 2:\n",
        "    print(\"pred: Gorila\")\n",
        "\n",
        "  return answer"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-7848fdb89e78>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mmodelo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'./modelo/modelo.h5'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mpesos_modelo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'./modelo/pesos.h5'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mcnn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodelo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mcnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpesos_modelo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/saving/save.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, options)\u001b[0m\n\u001b[1;32m    209\u001b[0m       \u001b[0mfilepath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpath_to_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m         \u001b[0mloader_impl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse_saved_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msaved_model_load\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/saved_model/loader_impl.py\u001b[0m in \u001b[0;36mparse_saved_model\u001b[0;34m(export_dir)\u001b[0m\n\u001b[1;32m    112\u001b[0m                   (export_dir,\n\u001b[1;32m    113\u001b[0m                    \u001b[0mconstants\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSAVED_MODEL_FILENAME_PBTXT\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m                    constants.SAVED_MODEL_FILENAME_PB))\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: SavedModel file does not exist at: ./modelo/modelo.h5/{saved_model.pbtxt|saved_model.pb}"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 172
        },
        "id": "zfRSCCAMZ2xw",
        "outputId": "c525a369-238e-4206-bc54-bd8fec32bb16"
      },
      "source": [
        "import sys #manejo de archivos \n",
        "import os #manejo de archivos \n",
        "from tensorflow.python.keras.preprocessing.image import ImageDataGenerator #ayuda a preprocesar imagenes de nuestro al\n",
        "from tensorflow.python.keras import optimizers #optimizador para entrenar nuesto algoritmo\n",
        "from tensorflow.python.keras.models import Sequential #permite hacer redes neuronales secuenciales, c/ capa eat en orden\n",
        "from tensorflow.python.keras.layers import Dropout, Flatten, Dense, Activation\n",
        "from tensorflow.python.keras.layers import  Convolution2D, MaxPooling2D #permiten convolucion y maxpooling\n",
        "from tensorflow.python.keras import backend as K #limpia sesion de keras corrienod en el background\n",
        "\n",
        "K.clear_session()\n",
        "\n",
        "\n",
        "\n",
        "data_entrenamiento = './data/entrenamiento'\n",
        "data_validacion = './data/validacion'\n",
        "\n",
        "\"\"\"\n",
        "Parameters\n",
        "\"\"\"\n",
        "epocas=20 #n° de veecs que vamos a iterar en nuestro set de datos en el entrenamiento\n",
        "longitud, altura = 150, 150 #tamaño de procesamiento de imagenes cambiando a 150pixeles\n",
        "batch_size = 32 #numero de imagenes que se manda a procesar en cada paso\n",
        "pasos = 1000 # de veces que se procesa la informacion en cada epoca (1epoca 1000pasos)\n",
        "validation_steps = 300 #despues de cada epoca de corren 300 pasos con nuestro set de datos de validacion, para que aprenda nuestro algoritmo\n",
        "filtrosConv1 = 32 #n°de filtros que va a tener una convolucion\n",
        "filtrosConv2 = 64\n",
        "tamano_filtro1 = (3, 3) #tamaño del filtro que usa la comvolucion\n",
        "tamano_filtro2 = (2, 2)\n",
        "tamano_pool = (2, 2) #tamaño de filtro en nuestro maxpooling\n",
        "clases = 3 #cantidad de clases de clasificacion de objetos(gatos, perros, etc)\n",
        "lr = 0.0004 #learning read es que tan grande hace los ajustes pa acercarse a una solucion optima\n",
        "\n",
        "\n",
        "##Preparamos nuestras imagenes\n",
        "# se crea un generador que dice como preprocesar nuestra informacion, para despues transformarlas\n",
        "entrenamiento_datagen = ImageDataGenerator( #importado en la linea 3\n",
        "    rescale=1./255, #reescala imagenes en vez de 1 a 255, todos nuestro valores de pixeles esten de 0 a 1, para hacer mas eficiente nuestro entrenamiento\n",
        "    shear_range=0.2, #genera nuestras imagenes pero las inclinar para que el algoritmo aprenda a detectar en otras posiciones\n",
        "    zoom_range=0.2, #genera nuestras imagenes pero les hace zoom para que el algoritmo aprenda a detectar imagenenes incompletas o secciones de esta\n",
        "    horizontal_flip=True) #toma una imagnes y la invierte para que aprenda a distinguir direccionalidad\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1. / 255) #pasamos las imagenes tal cual son\n",
        "\n",
        "\"\"\"entrenamiento_generador = entrenamiento_datagen.flow_from_directory(\n",
        "    data_entrenamiento, #entra a nuestro directorio a la carpeta entrenamiento y abre todas las imagenes a\n",
        "    target_size=(altura, longitud), # una altura y longitud especifica\n",
        "    batch_size=batch_size, #procesarno en un batch ground de 32 ya definido arriba\n",
        "    class_mode='categorical') #la clasificacion va a ser por categorias\n",
        "\n",
        "validacion_generador = test_datagen.flow_from_directory( #igal para validacion\n",
        "    data_validacion,\n",
        "    target_size=(altura, longitud),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical')\"\"\"\n",
        "\n",
        "entrenamiento_generador = entrenamiento_datagen.flow_from_directory(\n",
        "    data_entrenamiento,\n",
        "    target_size=(altura, longitud),\n",
        "    batch_size=batch_size,\n",
        " #   class_mode='categorical')\n",
        "\n",
        "validacion_generador = test_datagen.flow_from_directory(\n",
        "    data_validacion,\n",
        "    target_size=(altura, longitud),\n",
        "    batch_size=batch_size,\n",
        "#    class_mode='categorical')\n",
        "\n",
        "\n",
        "\n",
        "cnn = Sequential() #sera una red secuancial, es decir varias capas apiladas\n",
        "cnn.add(Convolution2D(filtrosConv1, tamano_filtro1, padding =\"same\", input_shape=(longitud, altura, 3), activation='relu')) #nuestra primera capa va a ser una convolucion,que va tener el numero de filtro definido, tamaño, padding le dice lo que hace nuetro filtro rn las esquinas, con imagenes a altura y longitud definida, funcion de activacion es relu\n",
        "cnn.add(MaxPooling2D(pool_size=tamano_pool)) #luego se hace un maxpoolingo con un filtro de tamaño ya definido\n",
        "\n",
        "cnn.add(Convolution2D(filtrosConv2, tamano_filtro2, padding =\"same\")) #igual al filtro uno pero sin definir otros parametros que ya fueron filtrados en la capa anterior\n",
        "cnn.add(MaxPooling2D(pool_size=tamano_pool))\n",
        "\n",
        "\n",
        "\"\"\"INICIO DE CLASIFICACION\"\"\"\n",
        "cnn.add(Flatten())#a las imagenes profundas la hacemos plana, en una imagen con toda la informacion de nuestra red neuronal\n",
        "cnn.add(Dense(256, activation='relu'))#mandamos la imagen anterior a una capa normal, donde la capa estara conectada con todas las neuronas de la capa anterior\n",
        "cnn.add(Dropout(0.5)) #durante el entrenamiento se le apaga un 50% de las neuronas cada paso para evitar sobre ajustar y no aprenda un caminoen especifico sino caminos alternos para recolectar data\n",
        "cnn.add(Dense(clases, activation='softmax'))#ultima capa de 3 neuronas, softmax nos da un porcentaje de posibilidades de que sea de cada clase\n",
        "\n",
        "cnn.compile(loss='categorical_crossentropy', #parametros para optimizar nuestro algoritmo:durante el entrenamiento ve la funcion de perdida, haciendo aproximaciones lr ya definidas, y la metrica es accuracy de que tan bien esta prendiendo\n",
        "            optimizer=optimizers.Adam(lr=lr),\n",
        "            metrics=['accuracy']) #porcentage de imagenes que esta clasificando bien\n",
        "\n",
        "\n",
        "\n",
        "\"\"\"ENTRENAR NUESTRO ALGORITMO\"\"\"\n",
        "cnn.fit_generator(\n",
        "    entrenamiento_generador, #le pasamos nuestra imagenes de entrenamiento\n",
        "    steps_per_epoch=pasos, #pasos por epocas\n",
        "    epochs=epocas,\n",
        "    validation_data=validacion_generador, #imegenes de validacion\n",
        "    validation_steps=validation_steps) #pasos de validacion que ejecuta por cada epoca\n",
        "\n",
        "\n",
        "\"\"\"GUARDAMOS NUESTRO MODELO EN UN ARCHIVO\"\"\"\n",
        "target_dir = './modelo/'\n",
        "if not os.path.exists(target_dir): # si no existe la carpeta la crea\n",
        "  os.mkdir(target_dir)\n",
        "cnn.save('./modelo/modelo.h5')\n",
        "cnn.save_weights('./modelo/pesos.h5') #pesos de cada capas que ya entrenamos"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-13-64f7a6c42066>\"\u001b[0;36m, line \u001b[0;32m71\u001b[0m\n\u001b[0;31m    cnn.add(Convolution2D(filtrosConv1, tamano_filtro1, padding =\"same\", input_shape=(longitud, altura, 3), activation='relu')) #nuestra primera capa va a ser una convolucion,que va tener el numero de filtro definido, tamaño, padding le dice lo que hace nuetro filtro rn las esquinas, con imagenes a altura y longitud definida, funcion de activacion es relu\u001b[0m\n\u001b[0m      ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    }
  ]
}